{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not detected. Enable GPU in Runtime settings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0ccb7",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 2: Clone Repository (n·∫øu ch∆∞a upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3945f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Clone t·ª´ GitHub (n·∫øu b·∫°n ƒë√£ push code l√™n)\n",
    "# !git clone https://github.com/YOUR_USERNAME/RAG_best_practices.git\n",
    "# %cd RAG_best_practices\n",
    "\n",
    "# Option B: Upload t·ª´ local\n",
    "# 1. Zip folder RAG_best_practices tr√™n m√°y local\n",
    "# 2. Upload l√™n Colab b·∫±ng c√°ch ch·∫°y cell d∆∞·ªõi:\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"Upload file RAG_best_practices.zip c·ªßa b·∫°n...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Unzip\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(f\"Extracted {filename}\")\n",
    "\n",
    "# Change to project directory\n",
    "%cd RAG_best_practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e2bdb",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 3: C√†i ƒë·∫∑t Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1701083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update requirements.txt ƒë·ªÉ d√πng faiss-gpu thay v√¨ faiss-cpu\n",
    "!pip install -q datasets==2.19.1\n",
    "!pip install -q faiss-gpu  # D√πng GPU version\n",
    "!pip install -q gensim==4.3.3\n",
    "!pip install -q hqq==0.2.2\n",
    "!pip install -q mauve-text==0.4.0\n",
    "!pip install -q numpy==1.26.4\n",
    "!pip install -q pandas==2.2.3\n",
    "!pip install -q rouge-score==0.1.2\n",
    "!pip install -q safetensors==0.4.5\n",
    "!pip install -q scikit-learn==1.5.2\n",
    "!pip install -q sentence-transformers==3.3.0\n",
    "!pip install -q spacy==3.7.6\n",
    "!pip install -q tqdm==4.67.0\n",
    "!pip install -q transformers==4.46.2\n",
    "!pip install -q accelerate  # ƒê·ªÉ d√πng device_map=\"auto\"\n",
    "!pip install -q bitsandbytes  # ƒê·ªÉ quantization\n",
    "\n",
    "# Download spacy model\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023be3c0",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 4: Download Resources (n·∫øu ch∆∞a c√≥ trong zip)\n",
    "\n",
    "N·∫øu b·∫°n ch∆∞a upload resources/ folder, download t·ª´ Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e88495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('resources'):\n",
    "    print(\"Downloading resources from Google Drive...\")\n",
    "    !gdown --folder https://drive.google.com/drive/folders/1_-2PHI0-Wz1VjnW5Yvy5Ne9C7mMWk1nf\n",
    "    # Ho·∫∑c mount Google Drive c·ªßa b·∫°n:\n",
    "    # from google.colab import drive\n",
    "    # drive.mount('/content/drive')\n",
    "    # !cp -r /content/drive/MyDrive/RAG_resources ./resources\n",
    "else:\n",
    "    print(\"‚úÖ Resources folder already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea188758",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 5: Clone Mixtral-Offloading (cho Mixtral-8x7B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dec0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('mixtral-offloading'):\n",
    "    !git clone https://github.com/dvmazur/mixtral-offloading.git\n",
    "    print(\"‚úÖ Mixtral-offloading cloned\")\n",
    "else:\n",
    "    print(\"‚úÖ Mixtral-offloading already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749871b4",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 6: Ki·ªÉm tra c·∫•u tr√∫c project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la\n",
    "print(\"\\nüìÅ Model folder:\")\n",
    "!ls model/\n",
    "print(\"\\nüìÅ Resources folder:\")\n",
    "!ls resources/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c86a2",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 7: Ch·∫°y Evaluation\n",
    "\n",
    "### Option 1: Ch·∫°y v·ªõi c·∫•u h√¨nh m·∫∑c ƒë·ªãnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluation.py --dataset truthfulqa --output-dir outputs --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1551ddd5",
   "metadata": {},
   "source": [
    "### Option 2: Ch·∫°y trong notebook (ƒë·ªÉ debug d·ªÖ h∆°n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fc134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Disable TensorFlow warnings\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import modules\n",
    "from model.index_builder import IndexBuilder\n",
    "from model.language_model import LanguageModel\n",
    "from model.model_loader import ModelLoader\n",
    "from model.rag import RAG\n",
    "from model.retriever import Retriever\n",
    "from config import configs_run1, configs_run2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5220b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "truthful_qa = load_dataset(\"truthful_qa\", \"generation\", split='validation').to_pandas()\n",
    "test_data = truthful_qa[['question', 'best_answer', 'correct_answers', 'incorrect_answers']].copy()\n",
    "test_data['correct_answers'] = test_data['correct_answers'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else [x])\n",
    "test_data['correct_answers'] = test_data['correct_answers'].apply(lambda x: [i for i in x if i])\n",
    "test_data['incorrect_answers'] = test_data['incorrect_answers'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else [x])\n",
    "test_data['incorrect_answers'] = test_data['incorrect_answers'].apply(lambda x: [i for i in x if i])\n",
    "test_data['best_answer'] = test_data['best_answer'].apply(lambda x: [x] if x else [])\n",
    "test_data = test_data[(test_data['correct_answers'].apply(len) > 1) & (test_data['incorrect_answers'].apply(len) > 1)]\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "print(f\"Test data size: {len(test_data)}\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ee57e",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 8: Xem Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sau khi ch·∫°y xong, xem results\n",
    "import glob\n",
    "\n",
    "result_files = glob.glob('outputs/*/*.pkl')\n",
    "print(f\"Found {len(result_files)} result files:\")\n",
    "for f in result_files:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Load v√† xem m·ªôt result\n",
    "if result_files:\n",
    "    df = pd.read_pickle(result_files[0])\n",
    "    print(f\"\\nSample from {result_files[0]}:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd619b1",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 9: Download Results v·ªÅ m√°y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ef032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "# Zip outputs folder\n",
    "!zip -r outputs.zip outputs/\n",
    "\n",
    "# Download\n",
    "files.download('outputs.zip')\n",
    "\n",
    "print(\"‚úÖ Results downloaded!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
